{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:e44d973bb25defb56e2a6e1da94ba813d4052a6cd82f2cfcdbbab6cc5c90f5dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Computational statistics I  \n",
      "Autumn 2017: Lecture 5\n",
      "\n",
      "# Resampling: permutation testing and bootstrap\n",
      "\n",
      "Antti Honkela  \n",
      "20 September 2017"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# $p$-values and null hypothesis significance testing\n",
      "\n",
      "* Null hypothesis significance testing is one of the most widely used statistical methods\n",
      "  1. Set up a null hypothesis $H_0$ and alternative hypothesis\n",
      "      $H_1$, select a test statistic to differentiate the hypotheses\n",
      "  2. Evaluate the *p-value*\n",
      "  3. Reject $H_0$ is the $p$-value is smaller than pre-selected significance level (often 0.05)\n",
      "* Typical example: do two samples $X$ and $Y$ come from the same\n",
      "    distribution\n",
      "* Standard solutions: Student's $t$-test, Wilcoxon rank-sum test\n",
      "* Question: What is the definition of the *p-value*?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# The definition of the $p$-value\n",
      "\n",
      "Probability, that under the null hypothesis, the test statistic\n",
      "would be at least as extreme as was observed.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# NHST pros, cons and caveats\n",
      "\n",
      "* Often provides useful information on statistical significance\n",
      "* But: unreliable if used incorrectly, can be easily gamed\n",
      "* Controls the error of incorrectly rejecting the null\n",
      "* But: multiple hypothesis testing makes this difficult\n",
      "* $p$-values from adaptive analyses not reliable\n",
      "* Need to be careful about what is being tested: one tail or two tails"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Permutation testing\n",
      "\n",
      "* Useful generic tool for generating $p$-values\n",
      "* Example: do two samples $X$ and $Y$ come from the same\n",
      "    distribution\n",
      "* Direct computational solution: generate samples from the null\n",
      "    by randomly permuting the labels\n",
      "    \n",
      "$$ p = \\frac{\\text{# of at least as extreme cases} + 1}{\\text{# of permutations} + 1} $$\n",
      "\n",
      "* Example: testing by using the absolute difference of the means as the test statistic"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "npr.seed(42)\n",
      "\n",
      "# Generate two samples\n",
      "a = npr.normal(size=20)\n",
      "b = npr.normal(size=20) + 0.5\n",
      "\n",
      "# Concatenate to form a whole\n",
      "x = np.concatenate((a, b))\n",
      "print(np.mean(a), np.mean(b))\n",
      "truediff = np.abs(np.mean(a) - np.mean(b))\n",
      "\n",
      "# Repeatedly randomly permute to mix the groups\n",
      "meandiffs = np.zeros(1000)\n",
      "for i in range(1000):\n",
      "    z = npr.permutation(x)\n",
      "    meandiffs[i] = np.abs(np.mean(z[0:20]) - np.mean(z[20:]))\n",
      "\n",
      "print((np.sum(truediff <= meandiffs)+1)/(len(meandiffs)+1))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.171298561442 0.234024884606\n",
        "0.204795204795\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Bootstrap sampling\n",
      "\n",
      "* How to get confidence intervals for general analysis\n",
      "    procedures?\n",
      "* In frequentist statistics, we are interested in performance\n",
      "    under repeated sampling from the true data generating mechanism\n",
      "    $p(x)$\n",
      "* Bootstrap principle: approximate $p(x)$ by sampling from the\n",
      "    empirical data distribution $p_e(x)$ with replacement\n",
      "* In the standard method, the bootstrap sample is always of the same size as the original data set\n",
      "* Evaluate confidence intervals within the bootstrap samples,\n",
      "    e.g. taking 5 % and 95 % quantiles\n",
      "* More accurate bias-corrected versions available\n",
      "* Example: confidence interval on the mean of a set of values\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "\n",
      "npr.seed(42)\n",
      "x = npr.normal(size=100)\n",
      "\n",
      "print(np.mean(x))\n",
      "means = np.zeros(1000)\n",
      "for i in range(1000):\n",
      "    I = npr.randint(100, size=100)\n",
      "    means[i] = np.mean(x[I])\n",
      "print(np.percentile(means, [5, 50, 95]))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.103846517394\n",
        "[-0.24211964 -0.10115503  0.04039439]\n"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}