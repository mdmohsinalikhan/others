{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:1c63d9cf8b05105481bef2c40c41e99b683277bd5803d91f6475aef07b66a38e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "University of Helsinki, Department of Mathematics and Statistics  \n",
      "MAST32001 Computational Statistics I, Autumn 2017  \n",
      "Antti Honkela  \n",
      "\n",
      "# Lecture 3: Numerical linear algebra, multivariate normals and numerical integration\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## Numerical linear algebra and multivariate normal distributions\n",
      "\n",
      "Multivariate normal distribution is one of the most commonly encountered distributions in statistics. The $d$-dimensional multivariate normal $\\mathcal{N}(\\mu, \\Sigma)$ is parametrised by the $d$-dimensional mean vector $\\mu$ and a symmetric positive-definite $d \\times d$ covariance matrix $\\Sigma$.\n",
      "\n",
      "Some important properties of symmetric positive-definite matrices:\n",
      "* all eigenvalues of symmetric matrices are real\n",
      "* all eigenvalues of symmetric positive-definite matrices are positive\n",
      "\n",
      "As before, numerical computation with floating point numbers can produce results that appear to violate these properties.\n",
      "\n",
      "In applications where this happens, it is usual practice to replace $\\Sigma$ with $\\Sigma + \\epsilon I_d$ where $I_d$ is the identity matrix and $\\epsilon > 0$ is chosen such that the sum is positive definite. (The sum will always be positive definite if $\\epsilon > |\\lambda_{\\text{min}}|$, where $\\lambda_{\\text{min}}$ is the smallest eigenvalue of $\\Sigma$, which would be negative in this case.)\n",
      "\n",
      "## 1. Generating multivariate normal random vectors\n",
      "\n",
      "Assuming we can generate univariate random numbers following $\\mathcal{N}(0, 1)$ (e.g. Box-Muller), we can form vectors of $d$ independently generated values to obtain multivariate normal vectors $x \\sim \\mathcal{N}(0, I_d)$, where $I_d$ is the $d$-dimensional identity matrix.\n",
      "\n",
      "In general, given a random variable $x$ with covariance $D$ and a fixed matrix $A$, the covariance of $Ax$ is $ADA^T$.\n",
      "\n",
      "We can thus use a linear transformation with matrix $A$ to obtain samples from $\\mathcal{N}(\\mu, \\Sigma)$, if we can find a matrix $A$ such that $A A^T = \\Sigma$. We can use the Cholesky decomposition of $\\Sigma$ to find such a matrix $A$.\n",
      "\n",
      "We will test generating and visualising multivariate random vectors in 2D.\n",
      "\n",
      "1. Construct a covariance matrix of 2D normal $$ \\Sigma = \\begin{pmatrix} \\sigma_1^2 & \\rho \\sigma_1 \\sigma_2 \\\\ \\rho \\sigma_1 \\sigma_2 & \\sigma_2^2 \\end{pmatrix} $$\n",
      "with $\\sigma_1 = 1, \\sigma_2 = 1, \\rho = 0.5$.\n",
      "2. Compute the Cholesky decomposition $A$ of $\\Sigma$.\n",
      "3. Use `numpy.random.normal()` to generate a 2x10000 matrix of independent $\\mathcal{N}(0,1)$ random numbers.\n",
      "4. Transform the matrix to vectors following $\\mathcal{N}(0, \\Sigma)$ by multiplying it by $A$. (Hint: Python uses `@` for matrix multiplication, i.e. `y = A @ x` )\n",
      "5. Plot the set of generated points as a scatter plot of points using matplotlib plot(). (Hint: try using the parameter `alpha` for partial transparency to get a better idea of the shape of the distribution.)\n",
      "6. Compute the eigenvectors of $\\Sigma$ and add them to the plot as lines starting from the mean. How can you interpret the eigenvectors and eigenvalues?\n",
      "7. Repeat the exercise using different values of $\\rho$, e.g. 0.1, 0.3, 0.7, 0.9, 0.95."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 2. Multivariate normal density\n",
      "\n",
      "The probability density of the d-dimensional multivariate normal distribution is\n",
      "$$ p(x) = (2 \\pi)^{-d/2} | \\det \\Sigma |^{-1/2} \\exp\\left( - \\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\right).$$\n",
      "\n",
      "Rather than working on the actual function, one usually works on its logarithm,\n",
      "$$ \\log p(x) = -\\frac{d}{2} \\log(2 \\pi) -\\frac{1}{2} \\log | \\det \\Sigma | - \\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu).$$\n",
      "\n",
      "This function is numerically difficult to evaluate because it contains the determinant $\\det \\Sigma$ and the quadratic form $(x-\\mu)^T \\Sigma^{-1} (x-\\mu)$. In applications where $\\Sigma$ can vary, $\\det \\Sigma$ can be very unstable. As a general rule, one should also never explicitly compute or use the inverse $\\Sigma^{-1}$.\n",
      "\n",
      "Fortunately the Cholesky decomposition provides an easy and computationally efficient solution to both these problems.\n",
      "\n",
      "1. Compute $\\log |\\det \\Sigma|$ using the Cholesky decomposition of $\\Sigma$ without using the determinant function. Remember that $\\det (AB) = \\det A \\cdot \\det B$, and that the Cholesky factor is lower triagonal, and that the determinant of a triagonal matrix is the product of the diagonal entries. Check your result against the direct computation using the function `numpy.linalg.slogdet()`, which robustly computes the log-determinant.\n",
      "2. Evaluate the quadratic form $(x-\\mu)^T \\Sigma^{-1} (x-\\mu)$ using the Cholesky decomposition of $\\Sigma$ without using the matrix inverse or the matrix $\\Sigma$ directly. (Hint: Try to represent $(x-\\mu)^T \\Sigma^{-1} (x-\\mu)$ as $(Bx)^T (Bx)$ for a suitable matrix B derived from the Cholesky decomposition. Use the function `scipy.linalg.solve_triangular` to solve the remaining linear system implied by the inverse.) Compare the values you obtain with direct computation.\n",
      "3. Repeat the example with changing the value of $\\rho$, especially for $\\rho \\rightarrow 1$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 3. High-dimensional normal random variables\n",
      "\n",
      "Many statistical problems involve relatively high-dimensional spaces that can be quite unintuitive. This exercise will highlight empirically a few less expected features of high-dimensional multivariate normal random variables.\n",
      "\n",
      "For each of the problems, you should generate random numbers following the $d$-dimensional multivariate normal distribution with covariance $I_d$.\n",
      "\n",
      "1. Distribution of the norms of the random vectors. Generate $d$-dimensional multivariate normal random variables for $d=1, 3, 10, 30, 100, 300, 1000$ and plot a histogram of their norms. What do you observe? How do these match the intuition of a low-dimensional bell-shaped curve with most of the probability near the origin.\n",
      "2. Distribution of the angles between pairs of random vectors. Generate pairs of $d$-dimensional multivariate normal random variables for $d=3, 10, 30, 100, 300, 1000$ and plot a histogram of the angles between them. What do you observe?\n",
      "\n",
      "Hint: $x \\cdot y = \\|x\\| \\|y\\| \\cos(\\angle(x, y))$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 4. Numerical integration by quadrature in 1D\n",
      "\n",
      "Many problems in statistics, especially Bayesian statistics reduce to computing integrals of functions. This can often be accomplished relatively easyly in finite intervals and low dimensions, but the problem becomes significantly more difficult as the dimensionality increases.\n",
      "\n",
      "As an example, let us consider the function\n",
      "$ f(x) = \\cos(\\| x \\|_2) p_x( x ), $\n",
      "where $p_x(x) = (2\\pi)^{(-D/2)} \\exp( - \\| x \\|_2^2 / 2 )$ is the density function of the multivariate normal distribution with identity covariance matrix $I_D$.\n",
      "\n",
      "Python module `scipy.integrate` contains many useful functions for computing such integrals that can be used in this exercise.\n",
      "\n",
      "1. Plot the function $f(x)$ on the interval $[-10, 10]$.\n",
      "2. Compute the integral $ \\int_0^1 f(x) \\mathrm{d}x $.\n",
      "3. Compute the integral $ \\int_0^3 f(x) \\mathrm{d}x $.\n",
      "4. Compute the integral $ \\int_0^10 f(x) \\mathrm{d}x $.\n",
      "5. Compute the integral $ \\int_0^\\infty f(x) \\mathrm{d}x $."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 5. Monte Carlo numerical integration\n",
      "\n",
      "Monte Carlo integration over a region $S$ of volume $V$ works by sampling $x_i \\sim \\mathrm{Uniform}(S)$ and reporting\n",
      "$$ \\int_V f(x) \\mathrm{d}x \\approx \\frac{V}{n} \\sum_{i=1}^n f(x_i). $$\n",
      "\n",
      "1. Implement Monte Carlo integration to compute the above 1D integral. Vary the number of samples $n = 10, 100, 1000, 10000$ and compare the accuracy of the Monte Carlo estimate to the value evaluated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 6. Numerical integration in higher dimensions\n",
      "\n",
      "1. Plot the function $f(x)$ in 2D in the region $[-10, 10] \\times [-10, 10]$.\n",
      "2. Compute the integral $ \\int_0^3 \\int_0^3 f(\\mathbf{x}) \\mathrm{d}\\mathbf{x} $ using a quadrature and Monte Carlo integration.\n",
      "3. Compute the integral $ \\int_0^3 \\int_0^3 \\int_0^3 f(\\mathbf{x}) \\mathrm{d}\\mathbf{x} $ using a quadrature and Monte Carlo integration.\n",
      "4. Compute the integral $ \\int_0^3 \\int_0^3 \\int_0^3 \\int_0^3 f(\\mathbf{x}) \\mathrm{d}\\mathbf{x} $ using a quadrature and Monte Carlo integration.\n",
      "\n",
      "Hint: some `scipy.integrate` functions such as `dblquad` and related functions require the integration bounds to be specified as functions. In case of constant bounds these can be specified using the `lambda` statement to generate anonymous functions. For example, `lambda x: 0` is an anonymous function whose value is identically 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}