{
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:3b468903d89f71a62d4ead544ef14746bea406feb3a0a53428bc759d009cbc4b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true,
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Computational statistics I  \n",
      "Autumn 2017: Lecture 8\n",
      "\n",
      "# Markov chain Monte Carlo in practice\n",
      "\n",
      "Antti Honkela  \n",
      "28 September 2017"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Recommended MCMC workflow\n",
      "\n",
      "1. Running three or more chains starting from very different points allows checking convergence.\n",
      "2. Samples from an initial **warm-up** or burn-in period (e.g. first 50% of samples) are discarded as they depend too much on the initial point.\n",
      "3. The proposal often needs to be tuned to get fast mixing. You should first perform any tuning, then discard all those samples and run the actual analysis. Note that the optimal tuning for warm-up and stationary phases might be different.\n",
      "4. Check for convergence by comparing the chains (see below)\n",
      "5. Mix the non-warm-up samples from all chains for final analysis.\n",
      "6. Compare your inferences with results from simpler models or approximations.\n",
      "\n",
      "(Gelman & Shirley, 2011; http://www.mcmchandbook.net/HandbookChapter6.pdf)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Important caveats\n",
      "\n",
      "### Adaptation\n",
      "\n",
      "* Standard MH theory assumes that the proposal does not depend on past samples. \n",
      "* Tuning the proposal or even adaptive termination criteria can break these assumptions.\n",
      "* There are adaptive samplers that can avoid these issues, but they are not very widely used.\n",
      "* Ignoring all samples from the tuning/tweaking phase is usually the best choice.\n",
      "\n",
      "### Convergence\n",
      "\n",
      "* It is in general impossible to prove a Markov chain has converged - you can never tell if you are just stuck exploring a local mode.\n",
      "* MCMC is in general a method for approximate inference even though some people claim it is exact."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Tuning the proposal distribution\n",
      "\n",
      "* An optimal proposal matches the target as closely as possible.\n",
      "* Usually we do not know the target very well, so generic proposals (such as Gaussian centered at current point) need to be used.\n",
      "\n",
      "\n",
      "* The optimal acceptance rate for Metropolis-Hastings is quite low: 50% (low dimensional) down to 23% (high dimensional).\n",
      "* High acceptance usually indicates too short steps, low acceptance indicates too long steps."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Diagnostics of sampling efficiency\n",
      "\n",
      "* Autocorrelation plot (Koistinen, Sec. 7.7)\n",
      "  $$ \\rho_k = \\frac{E[(X_i - \\mu)(X_{i+k} - \\mu)]}{\\sigma^2}, \\quad k = 0, 1, 2, \\dots $$\n",
      "  * $\\mu$ and $\\sigma^2$ computed from the samples\n",
      "* Note: $E[]$ here denotes the sample average over $X_1, \\dots, X_N$, i.e.\n",
      "  $$ \\rho_k = \\frac{\\frac{1}{N-k} \\sum_{i=1}^{N-k} (X_i - \\mu)(X_{i+k} - \\mu)}{\\sigma^2} $$\n",
      "\n",
      "\n",
      "* Effective sample size (Koistinen, Sec. 7.8) from $M$ samples\n",
      "  $$ \\mathrm{ESS} = \\frac{M}{1 + 2 \\sum_{k=1}^{M-1} (1 - \\frac{k}{M}) \\rho_k} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Convergence diagnostics\n",
      "\n",
      "* Potential scale reduction (R-hat, Gelman & Rubin, 1992)\n",
      "* Assume $x_{ij}$ is the $i$th sample (out of $n$) from chain $j$ (out of $m$)\n",
      "* Estimate within-chain variance $W$ and between-chains variance $B$\n",
      "* $ W = \\frac{1}{m} \\sum_{i=1}^m s_i^2 $, where $ s_i^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_{ij} - \\bar{x_j})^2 $\n",
      "* $ B = \\frac{n}{m-1} \\sum_{j=1}^m (\\bar{x}_j - \\bar{\\bar{x}})^2$, where $\\bar{x}_j = \\frac{1}{n} \\sum_{i=1}^n x_{ij}$ and $\\bar{\\bar{x}} = \\frac{1}{m} \\sum_{j=1}^m \\bar{x}_j$\n",
      "* $ \\mathrm{Var}(x) = \\left( 1 - \\frac{1}{n} \\right) W + \\frac{1}{n} B $\n",
      "* $ \\sqrt{\\hat{R}} = \\sqrt{\\frac{\\mathrm{Var}(x)}{W}} $\n",
      "* Target $\\hat{R}$ less than 1.1 or 1.2\n",
      "* Note: $\\hat{R}$ is defined for scalar variables. For vectors it is common to compute it for each component and take the maximum over different components."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## General debugging tips\n",
      "\n",
      "* Generate synthetic data from your model with known parameters and check if your inferences are consistent with those parameters."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}