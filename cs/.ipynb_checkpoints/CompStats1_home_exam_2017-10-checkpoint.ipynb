{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:3fe33a3f966e1a7180714d170fc773efb843d6823bf9803368e2fd02480fade2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "University of Helsinki, Department of Mathematics and Statistics  \n",
      "MAST32001 Computational Statistics I, Autumn 2017  \n",
      "Antti Honkela  \n",
      "\n",
      "# Home exam\n",
      "\n",
      "Please return your solutions for Problem 1 as a separate Python source file `problem1.py` and for Problems 2-6 as a notebook to Moodle.  \n",
      "Deadline: Wednesday 8 November at 23:55\n",
      "\n",
      "** Please answer 5 problems. **\n",
      "\n",
      "Please note that this exam is *not* teamwork. You should find the answers to the questions just by yourself with no help from others.\n",
      "\n",
      "## General instructions (IMPORTANT!)\n",
      "\n",
      "1. When returning your solutions, please make sure the notebook can be run cleanly using \"Cell\" / \"Run All\".\n",
      "2. Please make sure that your notebook will not depend on any local files.\n",
      "3. Please make sure that the solutions for each problem in your notebook will produce the same results when run multiple times, i.e. remember to seed any random number generators you use (`npr.seed()`!).\n",
      "4. Make sure you only use the functions specified in the statement of each problem.\n",
      "5. The problems are meant to be solved based on contents of the course. You should not search for solutions online and not use any solutions possibly found.\n",
      "\n",
      "## Updates / clarifications\n",
      "\n",
      "2017-10-23: Fixed a typo $n \\rightarrow r$ in Problem 1-1, added missing $\\log$ to Problem 1-2, clarified that `numpy.linalg` can be used in Problem 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 1. Numerical computation of probabilities\n",
      "\n",
      "For each of the cases below, write a function to compute the requested log-probabilities in a numerically stable manner. The functions will be tested on a number of inputs and the scoring depends on the number of cases handled correctly.\n",
      "\n",
      "Note: Your code may only use basic `numpy` functions including `numpy.linalg` and `scipy.special.gammaln()`.\n",
      "\n",
      "** Return your solution as a separate file `problem1.py` that contains the definitions of the two functions `lp1()` and `lp2()` as outlined below to Moodle. Your functions should return a single scalar value. **\n",
      "\n",
      "1. The log-probability $\\log p(NB(r, p) = k)$ of the negative binomial distribution when $ p(NB(r, p) = k) = \\binom{k+r-1}{k} (1-p)^r p^k $. Here $0 \\le p \\le 1$ and $k, r \\in \\{0, 1, 2, \\dots \\}$.\n",
      "2. The log-probability $\\log p(x \\mid \\mu, \\Sigma, \\pi) = \\log \\left(\\sum_{i=1}^N \\pi_i \\mathcal{N}(x;\\; \\mu_i, \\Sigma)\\right).$\n",
      "Here $0 \\le \\pi_i \\le 1$, $\\sum_{i=1}^N \\pi_i = 1$, $x_i, \\mu_i \\in \\mathbb{R}^d$ and $\\Sigma \\in \\mathbb{R}^{d \\times d}$ is symmetric and positive definite."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "#from scipy.stats import multivariate_normal\n",
      "\n",
      "\n",
      "def multi_normal_pdf(x_in, mu_in, Sigma_in):\n",
      "    d = len(x_in)\n",
      "    mu = mu_in.transpose()\n",
      "    x = x_in.transpose()\n",
      "    S = Sigma_in\n",
      "    A = np.linalg.cholesky(S)\n",
      "\n",
      "    log_det_S = 2*np.log(np.linalg.det(A))\n",
      "    y = np.linalg.solve(A, x - mu)\n",
      "    third_term = .5*np.dot(y.transpose(),y)\n",
      "    log_density = -.5*d*np.log(2*np.pi) - .5*log_det_S - third_term\n",
      "\n",
      "    return np.exp(log_density)\n",
      "\n",
      "def lp1(k, r, p):\n",
      "    \"\"\"Returns log p(NB(r, p) = k).\n",
      "    Input:\n",
      "    p: real, 0 <= p <= 1\n",
      "    r, k: integer, r > 0, k >= 0\"\"\"\n",
      "    coefficient = r\n",
      "    if k < 0 or r < 1:\n",
      "        raise ValueError('Invalid vlue of r or k')\n",
      "    else:\n",
      "        coefficient = math.factorial(k+r-1)/(math.factorial(k)*math.factorial(r-1))\n",
      "        \n",
      "    result = np.log(coefficient*((1-p)**r)*(p)**k)        \n",
      "    return result\n",
      "    #raise NotImplementedError('Not implemented yet')\n",
      "    \n",
      "def lp2(x, mu, Sigma, pi):\n",
      "    \"\"\"Returns log p(x | \\mu, \\Sigma, \\pi) = \\sum_{i=1}^N \\pi_i N(x; \\mu_i, \\Sigma)\n",
      "    Input:\n",
      "    x: np.array, shape: (d,)\n",
      "    mu: np.array, shape: (k, d)\n",
      "    Sigma: np.array, shape: (d, d)\n",
      "    pi: np.array, shape: (k,)\n",
      "    \"\"\"\n",
      "          \n",
      "    x_d = len(x)\n",
      "    mu_d = len(mu)\n",
      "    pi_d = len(pi)\n",
      "    sigma_d = len(Sigma)\n",
      "    \n",
      "    #print(\"the dimension of x is:\" + str(x_d))\n",
      "    #print(\"the dimension of mu is:\" + str(mu_d))\n",
      "    #print(\"the dimension of pi is:\" + str(pi_d))\n",
      "    #print(\"the dimension of Sigma is:\" + str(sigma_d))\n",
      "    \n",
      "    \n",
      "    if pi_d != mu_d:\n",
      "        raise ValueError('pi and mu have different dimensions') \n",
      "    \n",
      "    #for i in range(0,mu_d):\n",
      "     #   print(\"the dimension of mu \" + str(i) + \" is:\" + str(len(mu[i])))\n",
      "        \n",
      "        if x_d != len(mu[i]):\n",
      "            raise ValueError(\"x and mu\" + str(i)+\" have different dimensions\")\n",
      "            \n",
      "    if np.sum(pi)!= 1:\n",
      "        raise ValueError('pi does not sum up to 1')\n",
      "        \n",
      "    for i in pi:\n",
      "        if i < 0 or i > 1:\n",
      "            raise ValueError(\"Invalid value of pi\")\n",
      "    \n",
      "    if sigma_d != x_d:\n",
      "        raise ValueError(\"x and Sigma have different dimensions\")\n",
      "    else:\n",
      "        for i in range(0,sigma_d):\n",
      "            if len(Sigma[i]) != x_d:\n",
      "                raise ValueError(\"x and Sigma have different dimensions\")\n",
      "\n",
      "    result_before_log = 0\n",
      "    for i in range(1,mu_d+1):\n",
      "        result_before_log = result_before_log + pi[i-1]*multi_normal_pdf(x, mu[i-1], Sigma)\n",
      "    \n",
      "                \n",
      "    #raise NotImplementedError('Not implemented yet')NotImplementedError\n",
      "    return np.log(result_before_log)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Example invocations of the functions, should return a single scalar value\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "x = []\n",
      "y = []\n",
      "\n",
      "for i in range(0,100):\n",
      "    x.append(i)\n",
      "    y.append(np.exp(lp1(i, 10, 0.5)))\n",
      "plt.plot(x,y)\n",
      "\n",
      "del x[:]\n",
      "del y[:]\n",
      "\n",
      "for i in range(0,100):\n",
      "    x.append(i)\n",
      "    y.append(np.exp(lp1(i, 40, 0.5)))\n",
      "plt.plot(x,y)\n",
      "\n",
      "del x[:]\n",
      "del y[:]\n",
      "\n",
      "for i in range(0,100):\n",
      "    x.append(i)\n",
      "    y.append(np.exp(lp1(i, 70, 0.5)))\n",
      "plt.plot(x,y)\n",
      "\n",
      "#print(np.exp(lp1(1,1,0)))\n",
      "\n",
      "mu = np.array([[-10.0, -10.0], [10.0, 10.0], [0.0,0.0], [-10.0, 10.0], [10.0,-10.0]])\n",
      "Sigma = np.array([[1.0, 0.5], [0.5, 1.0]])\n",
      "pi = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
      "\n",
      "W = 100\n",
      "H = 100\n",
      "xAxis = np.linspace(-50,50,W)\n",
      "yAxis = np.linspace(-50,50,H)\n",
      "X,Y = np.meshgrid(xAxis, yAxis)\n",
      "Z = np.zeros((W,H))\n",
      "for i in range(0,W):\n",
      "    for j in range(0,H):\n",
      "        Z[i][j] = lp2(np.array([xAxis[i], yAxis[j]]),mu,Sigma,pi)\n",
      "\n",
      "plt.figure()\n",
      "plt.contour(X,Y,Z,20)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 2. Simulating random numbers with a given distribution\n",
      "\n",
      "For each of the cases below, write a function to simulate random numbers following the given distribution.\n",
      "Explain your solutions briefly and justify briefly why it works as stated.\n",
      "\n",
      "Note: Your code may only use basic `numpy` and `numpy.linalg` functions and `numpy.random.uniform()`.\n",
      "\n",
      "1. $\\mathcal{N}(\\mu, \\Sigma)$, where $\\mu = (1, 2)^T$ and $\\Sigma = \\begin{pmatrix} 1 & 2\\rho \\\\ 2\\rho & 4 \\end{pmatrix}$,\n",
      "where $\\rho = 0.8$. Draw 1000 samples and plot a scatter plot of them.\n",
      "2. $\\mathrm{Gamma}(\\alpha, \\beta)$ with $\\alpha = 3/2$ and $\\beta = 2$. Here the pdf of the distribution is\n",
      "$$ \\Gamma(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} \\exp(-\\beta x). $$\n",
      "Hint: use rejection sampling with $\\mathrm{Exponential}(\\lambda)$ proposal.\n",
      "Draw 1000 samples and plot a normed histogram of the samples.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "import matplotlib.pyplot as plt\n",
      "import sys\n",
      "\n",
      "def normal_pdf(x,mu,sigma):\n",
      "    return (1/((math.sqrt(2*3.14)*sigma)))*np.exp((-(x-mu)**2)/(2*sigma**2))\n",
      "\n",
      "def laplace_pdf(x,mu,b):\n",
      "    return (1/(2*b))*np.exp(-abs(x-mu)/b)\n",
      "\n",
      "def multi_normal_pdf(x_in, mu_in, Sigma_in):\n",
      "    d = len(x_in)\n",
      "    mu = mu_in.transpose()\n",
      "    x = x_in.transpose()\n",
      "    S = Sigma_in\n",
      "    A = np.linalg.cholesky(S)\n",
      "\n",
      "    log_det_S = 2*np.log(np.linalg.det(A))\n",
      "    y = np.linalg.solve(A, x - mu)\n",
      "    third_term = .5*np.dot(y.transpose(),y)\n",
      "    log_density = -.5*d*np.log(2*np.pi) - .5*log_det_S - third_term\n",
      "\n",
      "    return np.exp(log_density)\n",
      "\n",
      "xaxis = []\n",
      "yaxis = []\n",
      "xaxis_accepted = []\n",
      "yaxis_accepted = []\n",
      "mu1 = 1\n",
      "mu2 = 2\n",
      "mu = np.array([mu1,mu2])\n",
      "sigma1 = 1 #square root of variance. here variance of the first compontent is 1\n",
      "sigma2 = 2 #square root of variance. here variance of the second compontent is 4\n",
      "Sigma = np.array([[1, 2*0.8],[2*0.8, 4]])\n",
      "b1 = 1\n",
      "b2 = 5\n",
      "z = 0\n",
      "\n",
      "#X-axis\n",
      "for i in range(0,10**5):\n",
      "    y = np.random.uniform(0,1)\n",
      "    if y < .5:\n",
      "        x = np.log(2*y)*b1 + mu1 #  the inverse of the cdf of laplace\n",
      "    else:\n",
      "        x = -1*np.log(2*(1-y))*b1 + mu1  # the inverse of the cdf of laplace\n",
      "        \n",
      "    # x is accepted as a sample of laplace distribution according to the corollary in the lecture\n",
      "    u = np.random.uniform(0,1)\n",
      "    if u < (normal_pdf(x,mu1,sigma1))/(1.5*laplace_pdf(x,mu1,b1)):\n",
      "        z = x\n",
      "        y = np.random.uniform(0,1)\n",
      "        if y < .5:\n",
      "            x = np.log(2*y)*b2 + mu2 #  the inverse of the cdf of laplace\n",
      "        else:\n",
      "            x = -1*np.log(2*(1-y))*b2 + mu2  # the inverse of the cdf of laplace\n",
      "            \n",
      "        u = np.random.uniform(0,1)\n",
      "        if u < (normal_pdf(x,mu2,sigma2))/(2*laplace_pdf(x,mu2,b2)):\n",
      "            xaxis.append(z)\n",
      "            yaxis.append(x)\n",
      "            u = np.random.uniform(0,1)\n",
      "            if u < (multi_normal_pdf(np.array([z,x]),mu,Sigma))/(2*normal_pdf(z,mu1,sigma1)*normal_pdf(x,mu2,sigma2)):\n",
      "                xaxis_accepted.append(z)\n",
      "                yaxis_accepted.append(x)\n",
      "            \n",
      "bins = np.linspace(-10, 10, 50)\n",
      "plt.hist(xaxis,bins,normed = True)\n",
      "plt.hist(yaxis,bins,normed = True)\n",
      "\n",
      "t1 = np.arange(-10, 10, .001)\n",
      "plt.plot(t1,normal_pdf(t1,mu1,sigma1))\n",
      "plt.plot(t1,normal_pdf(t1,mu2,sigma2))\n",
      "\n",
      "plt.scatter(yaxis_accepted,xaxis_accepted)\n",
      "\n",
      "\n",
      "W = 100\n",
      "H = 100\n",
      "xAxis = np.linspace(-10,10,W)\n",
      "yAxis = np.linspace(-10,10,H)\n",
      "X,Y = np.meshgrid(xAxis, yAxis)\n",
      "Z = np.zeros((W,H))\n",
      "for i in range(0,W):\n",
      "    for j in range(0,H):\n",
      "        Z[i][j] = multi_normal_pdf(np.array([xAxis[i], yAxis[j]]),mu,Sigma)\n",
      "\n",
      "#plt.figure()\n",
      "plt.contour(X,Y,Z,100)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "### Your textual answer explaining your solutions:\n",
      "\n",
      "*replace this with your answer*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 3. Automatic testing of exercise solutions\n",
      "\n",
      "A teacher of a course in computational statistics is developing exercises for the students. The exercises are checked by an automated system that can be set to accept answers falling to a specified interval $[l, u]$. The exercises involve randomness so the lecturer cannot be certain what values the students will get. The lecturer wants to set up the system so that it will accept the solutions obtained by the students after running a given number of iterations with a high probability.\n",
      "\n",
      "In their exercise task, the students are studying the bootstrap confidence intervals of the mean absolute deviation (MAD)\n",
      "$$MAD = \\frac{1}{N} \\sum_{i=1}^N |x_i - \\bar{x}|, \\quad \\text{where } \\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i.$$\n",
      "The students' task is to draw 1000 bootstrap samples and estimate the central 95% confidence interval from the samples.\n",
      "\n",
      "Your task is to develop a bootstrap method the teacher could use to estimate a central 95% confidence interval for the values the students will obtain from their simulation. The teacher is in a hurry, so he has only enough time to run 10000 bootstrap samples of the original problem but can perform further subsampling of these results.\n",
      "\n",
      "Write a function to perform this task, given a 1D numpy array of numbers $x_i$.\n",
      "\n",
      "Explain the outline of your solution and justify why it works. Test your solution on the data set loaded below and report the confidence intervals obtained for the lower and upper ends of the confidence intervals obtained by the students.\n",
      "\n",
      "You may use basic `numpy`, `numpy.random` and `matplotlib` functions for the task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "\n",
      "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/toydata.txt', header=None)\n",
      "data = dataframe.values[:,0]\n",
      "print(np.mean(data), np.std(data))"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "### Your textual answer explaining your solutions:\n",
      "\n",
      "*replace this with your answer*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 4. Fix my MCMC\n",
      "\n",
      "Which of the MCMC algorithms presented below will converge to produce samples from the intended target distribution? Justify your answers briefly.\n",
      "\n",
      "For each sampler that will not converge to the correct distribution, suggest a change to fix it to sample from the intended target distribution. Your fix should keep the function for drawing samples from the proposal the same if possible and only change it if there is no other way to fix the sampler.\n",
      "\n",
      "** Note: you do not need to run any code, answering the questions and providing code for the fixed functions is enough. **\n",
      "\n",
      "In all cases we assume we are using a Metropolis-Hastings sampler that takes three arguments: the log-target function `ltarget(x)`, proposal density `eval_logq(xp, x)` evaluating $\\log q(x';x)$, i.e. the probability of proposing $x'$ when the current state is $x$, and a function `sample_q(x)` to draw samples $x'$ from the proposal $q(x' ; x)$. The following code is used to draw the samples and check for acceptance:\n",
      "``` {python}\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "\n",
      "x_prop = sample_q(x)\n",
      "accrate = np.min(1, np.exp(ltarget(x_prop) + eval_logq(x, xp) - ltarget(x) - eval_logq(xp, x)))\n",
      "```\n",
      "\n",
      "The problems:\n",
      "\n",
      "1. ``` {python}\n",
      "    def ltarget1(x):\n",
      "        if 2 < np.abs(x) and np.abs(x) < 3:\n",
      "            return 0\n",
      "        else:\n",
      "            return -np.inf\n",
      "    \n",
      "    def eval_logq1(xp, x):\n",
      "        return 0\n",
      "    \n",
      "    def sample_q1(x):\n",
      "        return x + npr.uniform(-1.0, 1.0)\n",
      "```\n",
      "2. ``` {python}\n",
      "    def ltarget2(x):\n",
      "        if 2 < np.abs(x) and np.abs(x) < 3:\n",
      "            return 0\n",
      "        else:\n",
      "            return -np.inf\n",
      "    \n",
      "    def eval_logq2(xp, x):\n",
      "        return 0\n",
      "    \n",
      "    def sample_q2(x):\n",
      "        return x + 0.01 * npr.normal()\n",
      "```\n",
      "3. ``` {python}\n",
      "    def ltarget3(x):\n",
      "        return -np.abs(x)\n",
      "    \n",
      "    def eval_logq3(xp, x):\n",
      "        return 0\n",
      "    \n",
      "    def sample_q3(x):\n",
      "        return x + 0.01 * npr.normal()\n",
      "```\n",
      "4. ``` {python}\n",
      "    def ltarget4(x):\n",
      "        return -np.abs(x)\n",
      "    \n",
      "    def eval_logq4(xp, x):\n",
      "        return 0\n",
      "    \n",
      "    def sample_q4(x):\n",
      "        return npr.normal()\n",
      "```\n",
      "5. ``` {python}\n",
      "    def ltarget5(x):\n",
      "        if x > 0:\n",
      "            return -x\n",
      "        else:\n",
      "            return -np.inf\n",
      "    \n",
      "    def eval_logq5(xp, x):\n",
      "        return 0\n",
      "    \n",
      "    def sample_q5(x):\n",
      "        return npr.uniform(np.max(0, x-1.0), x+1.0)\n",
      "```\n",
      "6. ``` {python}\n",
      "    def lnormpdf(x, mu, sigma):\n",
      "        \"\"\"Returns the log of normal pdf with mean mu and sd sigma, evaluated at x\"\"\"\n",
      "        return -0.5*np.log(2*np.pi*sigma**2) - 0.5*(x-mu)**2/sigma**2\n",
      "\n",
      "    def ltarget6(x):\n",
      "        return -np.abs(x)\n",
      "    \n",
      "    def eval_logq6(xp, x):\n",
      "        return lnormpdf(xp, x, 1) + lnormpdf(xp, x+1, 1)\n",
      "    \n",
      "    def sample_q6(x):\n",
      "        return x + npr.normal(0, 1) + npr.normal(1, 1)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "### Your answer:\n",
      "\n",
      "Mark if the samplers will converge by removing the wrong answer\n",
      "1. yes/no\n",
      "2. yes/no\n",
      "3. yes/no\n",
      "4. yes/no\n",
      "5. yes/no\n",
      "6. yes/no\n",
      "\n",
      "Explain how to fix the samplers that did not converge to the correct distribution:\n",
      "*replace this with your answer*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 5. MCMC sampling of Gaussian process hyperparameters\n",
      "\n",
      "Implement an MCMC sampler to draw samples from the posterior distribution of the model outlined below. Pay special attention to making sure your sampler is properly tuned to work efficiently and has converged properly.\n",
      "\n",
      "As our model we will consider a Gaussian process fitted to points $\\mathcal{D} = ((x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n))$. The code below will load the vectors $x$ and $y$.\n",
      "\n",
      "According to our model\n",
      "$$ y \\sim \\mathcal{GP}(0, k(x, x')), $$\n",
      "where $k(x, x')$ is the covariance function defined below. The covariance function, evaluated at pairs of points $x_1, x_2, \\dots, x_n$ defines the covariance matrix $K$ via\n",
      "$$ K_{ij} = k(x_i, x_j). $$\n",
      "In turn, the covariance matrix $K$ defines the probability model for $y$\n",
      "$$ p(y | K) = \\mathcal{N}(y ;\\; 0, K). $$\n",
      "\n",
      "The values $x_1, \\dots, x_n$ are the *input values* that define the covariance $K$ of the points $y_1, \\dots, y_n$ as a function of the parameters $\\alpha, \\sigma_f^2, \\sigma_n^2$. All parameters are constrained to be positive: $\\alpha > 0, \\sigma_f^2 > 0, \\sigma_n^2 > 0$.\n",
      "\n",
      "In this exercise we shall use the *rational quadratic* covariance which defines the covariance of $y_i$ and $y_j$ by\n",
      "$$ K_{ij} = \\mathrm{Cov}(y_i, y_j) = k(x_i, x_j) = \\sigma_f^2 (1 + (x_i - x_j)^2)^{-\\alpha} + \\sigma_n^2 \\delta_{ij}, $$\n",
      "where $\\delta_{ij}$ is the Kronecker $\\delta$-function\n",
      "$$ \\delta_{ij} = \\begin{cases} 1, \\quad \\text{if } i = j \\\\ 0, \\quad \\text{if } i \\neq j \\end{cases} $$\n",
      "\n",
      "After marginalising out the process, the log-marginal likelihood of the model, which is the target log-likelihood of the sampler, is\n",
      "$$ \\mathcal{L}(\\alpha, \\sigma_f^2, \\sigma_n^2) = -\\frac{1}{2}(y - \\mu)^T K^{-1} (y - \\mu) -\\frac{1}{2}\\log|K| -\\frac{n}{2} \\log 2\\pi, $$\n",
      "where we assume $\\mu = 0$.\n",
      "\n",
      "We set the following priors for the parameters:\n",
      "$$ p(\\alpha) = \\mathrm{Gamma}(\\alpha_\\alpha, \\beta_\\alpha) \\\\\n",
      "   p(\\sigma_f^2) = \\mathrm{Gamma}(\\alpha_f, \\beta_f) \\\\\n",
      "   p(\\sigma_n^2) = \\mathrm{Gamma}(\\alpha_n, \\beta_n) $$\n",
      "with parameters $\\alpha_\\alpha = 3, \\beta_\\alpha = 1, \\alpha_f = 2, \\beta_f = 2, \\alpha_n = 2, \\beta_n = 2$.\n",
      "\n",
      "Write an MCMC sampler to sample from the joint posterior distribution of $\\alpha, \\sigma_f^2, \\sigma_n^2$.\n",
      "Compute and print the posterior medians as well as 5% and 95% quantiles of the marginal posteriors of each variable.\n",
      "Plot scatter plots with 1000 representative points from the pairwise marginal distributions of all pairs of variables.\n",
      "\n",
      "You may use `numpy`, `numpy.random`, `scipy.special`, `matplotlib` and `autograd` functions for the task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/gp_data.txt', header=None, sep='\\t')\n",
      "x = dataframe.values[:,0]\n",
      "y = dataframe.values[:,1]\n",
      "plt.plot(x, y)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "## 6. ABC inference for the Black-Scholes model\n",
      "\n",
      "The data set loaded below is known to follow the Black-Scholes diffusion equation\n",
      "$$ \\begin{cases} \\mathrm{d}X(t) = \\mu X \\mathrm{d}t + \\sigma X \\mathrm{d}W_t \\\\ X(0) = 1 \\end{cases}$$\n",
      "that is an important model in finance. Here $W_t$ denotes the standard Wiener process (Brownian motion) for which $W_s - W_t \\sim \\mathcal{N}(0, |s-t|)$. The data set has been simulated with a time step of 1/200 and runs from t=0 to t=1.\n",
      "\n",
      "Our priors for $\\mu$ and $\\sigma$ are\n",
      "$$ p(\\mu) = \\mathrm{Gamma}(\\mu;\\; \\alpha_\\mu, \\beta_\\mu) \\\\\n",
      "   p(\\sigma) = \\mathrm{Gamma}(\\sigma;\\; \\alpha_\\sigma, \\beta_\\sigma) $$\n",
      "with $\\alpha_\\mu = \\alpha_\\sigma = 2$, $\\beta_\\mu = \\beta_\\sigma = 4$.\n",
      "\n",
      "Design and implement an ABC sampler to infer an approximate posterior distribution over $\\mu$ and $\\sigma$.\n",
      "You can use the Euler-Maruyama numerical stochastic differential equation solver provided below to simulate solutions of the equation. In order to match the true sequence, you should use `x0=np.array([1.0]), dt=1/200, steps=200`.\n",
      "\n",
      "Plot normed histograms of the marginal posterior distributions and print the posterior means and standard deviations of both parameters.\n",
      "Also plot a scatter plot of the joint posterior of the two parameters.\n",
      "\n",
      "Define the summary statistics you use and motivate briefly why you believe they fit this problem well.\n",
      "\n",
      "Please limit your solution to a runtime of max 1 minute.\n",
      "\n",
      "Hint: you will need to define suitable summary statistics for the rejection. Try to find summary statistics that yield an informative approximate posterior instead of just returning the prior or something close to it. As the generated paths are continuous, it may be useful to use of the increments X(t+dt) - X(t) when defining the summary statistics.\n",
      "\n",
      "You may use `numpy`, `numpy.random` and `matplotlib` functions for the task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def euler_maruyama_solver(x0, dt, steps, a, b):\n",
      "    \"\"\"Euler-Maruyama algorithm for numerical solution of the stochastic differential equation\n",
      "      dX(t) = a(t, X) dt + b(t, X) dW_t\n",
      "      X(0) = x0\n",
      "    Input:\n",
      "    x0: initial state, np.array, shape: (d, )\n",
      "    dt: time step, real\n",
      "    steps: number of steps, integer\n",
      "    a: function with two inputs a(t, X), returns np.array, shape: (d, )\n",
      "    b: function with two inputs b(t, X), returns np.array, shape: (d, )\n",
      "    \"\"\"\n",
      "    d = len(x0)\n",
      "    x = np.zeros((steps+1, d))\n",
      "    x[0,:] = x0\n",
      "    for i in range(steps):\n",
      "        x[i+1,:] = x[i,:] + a(i*dt, x[i,:]) * dt + b(i*dt, x[i,:]) * np.sqrt(dt) * npr.normal(size=d)\n",
      "    return x\n",
      "\n",
      "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/black-scholes_data.txt', header=None)\n",
      "data = dataframe.values[:,0]\n",
      "plt.plot(np.linspace(0, 1, 201), data)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "### Your textual answer explaining your solutions:\n",
      "\n",
      "*replace this with your answer*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}