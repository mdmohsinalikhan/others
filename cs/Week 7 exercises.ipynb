{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "",
  "signature": "sha256:407ec2e679c2a39368971255140ac61bcdbc5371fb5531e4fd9124e11f1f25a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "University of Helsinki, Department of Mathematics and Statistics  \n",
      "MAST32001 Computational Statistics I, Autumn 2017  \n",
      "Antti Honkela  \n",
      "\n",
      "# Week 7 exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Convergence checking for MCMC\n",
      "\n",
      "In this exercise we will revisit the 2D density considered in Exercise 4 on Week 6 but with $R=4.0$:\n",
      "$$ P^*(x; R) = \\sum_{i=1}^5 \\exp\\left( -\\frac{i}{2} (x-\\mu_i)^T (x - \\mu_i) \\right) $$\n",
      "with $\\mu_1 = (0, 0), \\mu_2 = (R, R), \\mu_3 = (R, -R), \\mu_4 = (-R, R), \\mu_5 = (-R, -R)$. Here $R$ denotes a parameter that specifies the spread of the modes of the distribution which we fix to $R=4.0$. (Please note the $i$ in $\\frac{i}{2}$ inside the $\\exp()$!)\n",
      "\n",
      "Unlike last week when many students had problems with convergence and obtaining sufficiently accurate results, we will apply rigorous convergence checking to make sure the results will be accurate.\n",
      "\n",
      "1. Implement a proper MCMC convergence checking framework (see Lecture 8) by running 5 chains using your sampler of choice, started from different corners of the distribution. Run the sampler so that you always double the number of samples drawn until the chains satisfy $\\hat{R} < 1.1$ for every variable.\n",
      "2. Report the $\\hat{R}$ values (see Lecture 8) you obtained for $x_1$ and $x_2$ in Moodle.\n",
      "3. Report $\\sqrt{\\mathrm{E}[(x_1-1)^2]}$ and $\\sqrt{\\mathrm{E}[(x_2-1)^2]}$ in Moodle. The required tolerance is $\\pm 0.2$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import numpy as np\n",
      "#import numpy.random as npr\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.special\n",
      "from scipy.stats import multivariate_normal\n",
      "\n",
      "import autograd.numpy as np\n",
      "import autograd.numpy.random as npr\n",
      "import autograd\n",
      "\n",
      "import autograd.numpy.linalg as npl\n",
      "\n",
      "\n",
      "\n",
      "mu1 = np.array([0,0])\n",
      "mu2 = np.array([4,4])\n",
      "mu3 = np.array([4,-4])\n",
      "mu4 = np.array([-4,4])\n",
      "mu5 = np.array([-4,-4])\n",
      "Sigma = np.array([[1.0, .8],[.8, 1.0]])\n",
      "\n",
      "def normal_pdf(x,mean,sd):\n",
      "    return (1/(np.sqrt(2*3.14)*sd))*np.exp(-((x-mean)**2)/(2*sd**2))\n",
      "\n",
      "def target(x):\n",
      "    sum = 0\n",
      "    \n",
      "    x_minus_mu1 = np.array([x[0]-mu1[0],x[1]-mu1[1]])\n",
      "    x_minus_mu2 = np.array([x[0]-mu2[0],x[1]-mu2[1]])\n",
      "    x_minus_mu3 = np.array([x[0]-mu3[0],x[1]-mu3[1]])\n",
      "    x_minus_mu4 = np.array([x[0]-mu4[0],x[1]-mu4[1]])\n",
      "    x_minus_mu5 = np.array([x[0]-mu5[0],x[1]-mu5[1]])\n",
      "    \n",
      "    sum = sum + np.exp((-1/2)*(x_minus_mu1[0]*x_minus_mu1[0] + x_minus_mu1[1]*x_minus_mu1[1]))\n",
      "    sum = sum + np.exp((-2/2)*(x_minus_mu2[0]*x_minus_mu2[0] + x_minus_mu2[1]*x_minus_mu2[1]))\n",
      "    sum = sum + np.exp((-3/2)*(x_minus_mu3[0]*x_minus_mu3[0] + x_minus_mu3[1]*x_minus_mu3[1]))\n",
      "    sum = sum + np.exp((-4/2)*(x_minus_mu4[0]*x_minus_mu4[0] + x_minus_mu4[1]*x_minus_mu4[1]))\n",
      "    sum = sum + np.exp((-5/2)*(x_minus_mu5[0]*x_minus_mu5[0] + x_minus_mu5[1]*x_minus_mu5[1]))\n",
      "    \n",
      "    return np.log(sum)\n",
      "\n",
      "def drawproposal(x,sd):\n",
      "    return npr.normal(x,sd)\n",
      "\n",
      "def proposal(x,x_given):\n",
      "    var = multivariate_normal(mean=x_given, cov=Sigma)\n",
      "    return var.pdf(x)\n",
      "\n",
      "def mhsample(x0, n):\n",
      "    x = x0\n",
      "    lp = target(x)\n",
      "    xs = []\n",
      "    for i in range(n):\n",
      "        x_prop = npr.multivariate_normal(x,Sigma)\n",
      "        l_prop = target(x_prop)\n",
      "        proposal(x, x_prop)\n",
      "        if npr.rand() < (l_prop/lp)*(proposal(x, x_prop)/proposal(x_prop, x)):\n",
      "            x = x_prop\n",
      "            lp = l_prop\n",
      "        xs.append(x)\n",
      "    return xs\n",
      "\n",
      "def compute_s_i_square(component,n,chainj,x_j_bar):\n",
      "    sum = 0\n",
      "    for i in chainj:\n",
      "        sum = sum + (i[component]-x_j_bar)**2\n",
      "    return (1/(n-1))*sum\n",
      "\n",
      "def compute_x_j_bar(component,n,chainj):\n",
      "    sum = 0\n",
      "    for i in chainj:\n",
      "        sum = sum + i[component]\n",
      "    return (1/n)*sum\n",
      "\n",
      "def compute_R_hat(component,n,chain1,chain2,chain3,chain4,chain5):\n",
      "    x_1_bar = compute_x_j_bar(component,n,chain1)\n",
      "    x_2_bar = compute_x_j_bar(component,n,chain2)\n",
      "    x_3_bar = compute_x_j_bar(component,n,chain3)\n",
      "    x_4_bar = compute_x_j_bar(component,n,chain4)\n",
      "    x_5_bar = compute_x_j_bar(component,n,chain5)\n",
      "    x_double_bar = (1/5)*(x_1_bar + x_2_bar + x_3_bar + x_4_bar + x_5_bar)\n",
      "    #print(x_double_bar)\n",
      "    B = (n/(5-1))*((x_1_bar-x_double_bar)**2 + (x_2_bar-x_double_bar)**2 + (x_3_bar-x_double_bar)**2 + (x_4_bar-x_double_bar)**2 + (x_5_bar-x_double_bar)**2)\n",
      "    #print(\"Here is the value of B: \" + str(B))\n",
      "    s_1_square = compute_s_i_square(component,n,chain1,x_1_bar)\n",
      "    s_2_square = compute_s_i_square(component,n,chain2,x_2_bar)\n",
      "    s_3_square = compute_s_i_square(component,n,chain3,x_3_bar)\n",
      "    s_4_square = compute_s_i_square(component,n,chain4,x_4_bar)\n",
      "    s_5_square = compute_s_i_square(component,n,chain5,x_5_bar)\n",
      "    W = (1/5)*(s_1_square + s_2_square + s_3_square + s_4_square + s_5_square )\n",
      "    #print(\"Here is the value of W: \" + str(W))\n",
      "    var_x = (1-1/n)*W + (1/n)*B\n",
      "    R_hat = var_x/W\n",
      "    return R_hat\n",
      "\n",
      "def hmc(x0, M, target, epsilon0, L):\n",
      "    xs = np.zeros([M, len(x0)])\n",
      "    gradF = autograd.grad(target)\n",
      "    x = np.copy(x0)\n",
      "    g = gradF(x)  # set gradient using initial x\n",
      "    logP = target(x0)  # set objective function too\n",
      "    accepts = 0\n",
      "    for m in range(2*M): # draw M samples after M warm-up iterations\n",
      "        p = npr.normal(size=x.shape)  # initial momentum is Normal(0,1)\n",
      "        H = p.T @ p / 2 - logP   # evaluate H(x,p)\n",
      "        xnew = np.copy(x)\n",
      "        gnew = np.copy(g)\n",
      "        for l in range(L): # make L \u2018leapfrog\u2019 steps\n",
      "            epsilon = npr.uniform(0.8, 1.2) * epsilon0  # optional: randomise epsilon for improved theoretical convergence properties\n",
      "            p = p + epsilon * gnew / 2   # make half-step in p\n",
      "            xnew = xnew + epsilon * p    # make step in x\n",
      "            gnew = gradF(xnew)           # find new gradient\n",
      "            p = p + epsilon * gnew / 2   # make half-step in p\n",
      "        logPnew = target(xnew)   # find new value of H\n",
      "        Hnew = p.T @ p / 2 - logPnew\n",
      "        dH = Hnew - H    # Decide whether to accept\n",
      "        if dH < 0 or np.log(npr.rand()) < -dH:\n",
      "            g = gnew\n",
      "            x = xnew\n",
      "            logP = logPnew\n",
      "            accepts += 1\n",
      "        if m >= M:\n",
      "            xs[m-M,:] = x\n",
      "    #print('Acceptance rate:', accepts/(2*M))\n",
      "    return xs\n",
      "    \n",
      "def compute_expectations(chain1,chain2,chain3,chain4,chain5):\n",
      "    x1 = []\n",
      "    x2 = []\n",
      "    for i in chain1:\n",
      "        x1.append((i[0]-1)**2)\n",
      "        x2.append((i[1]-1)**2)\n",
      "    for i in chain2:\n",
      "        x1.append((i[0]-1)**2)\n",
      "        x2.append((i[1]-1)**2)\n",
      "    for i in chain3:\n",
      "        x1.append((i[0]-1)**2)\n",
      "        x2.append((i[1]-1)**2)\n",
      "    for i in chain4:\n",
      "        x1.append((i[0]-1)**2)\n",
      "        x2.append((i[1]-1)**2)\n",
      "    for i in chain5:\n",
      "        x1.append((i[0]-1)**2)\n",
      "        x2.append((i[1]-1)**2)\n",
      "        \n",
      "    print(\"The square root of the mean of (x1-1)**2 is:\")\n",
      "    print(np.sqrt(np.mean(x1)))\n",
      "    print(\"The square root of the mean of (x2-1)**2 is:\")\n",
      "    print(np.sqrt(np.mean(x2)))\n",
      "    \n",
      "n = 4\n",
      "starting_point1 = np.array([0.0,0.0])\n",
      "starting_point2 = np.array([4.0,4.0])\n",
      "starting_point3 = np.array([4.0,-4.0])\n",
      "starting_point4 = np.array([-4.0,4.0])\n",
      "starting_point5 = np.array([-4.0,-4.0])\n",
      "while True:\n",
      "    n = 2*n\n",
      "    chain1 = hmc(starting_point1, n, lambda x: target(x), 0.2, 10)\n",
      "    chain2 = hmc(starting_point2, n, lambda x: target(x), 0.2, 10)\n",
      "    chain3 = hmc(starting_point3, n, lambda x: target(x), 0.2, 10)\n",
      "    chain4 = hmc(starting_point4, n, lambda x: target(x), 0.2, 10)\n",
      "    chain5 = hmc(starting_point5, n, lambda x: target(x), 0.2, 10)\n",
      "    print(\"the value of n is: \" + str(n))\n",
      "    R_hat_x1 = compute_R_hat(0,n,chain1,chain2,chain3,chain4,chain5)\n",
      "    R_hat_x2 = compute_R_hat(1,n,chain1,chain2,chain3,chain4,chain5)\n",
      "    \n",
      "    #print(chain1)\n",
      "    #print(chain2)\n",
      "    #print(chain3)\n",
      "    #print(chain4)\n",
      "    #print(chain5)\n",
      "    \n",
      "    #print(\"and the corresponding R_hat is:\")\n",
      "    if R_hat_x1 >= R_hat_x2:\n",
      "        R_hat = R_hat_x1\n",
      "    else:\n",
      "        R_hat = R_hat_x2\n",
      "        \n",
      "    print(\"R_hat of x1: \" + str(R_hat_x1))\n",
      "    print(\"R_hat of x2: \" + str(R_hat_x2))\n",
      "    print(\"R_hat:\" + str(R_hat))\n",
      "    if R_hat <= 1.1:\n",
      "    #if n == 32:\n",
      "        print(\"program is ending.\")\n",
      "        compute_expectations(chain1,chain2,chain3,chain4,chain5)\n",
      "        break\n",
      "\n",
      "#print(chain1[0][1])\n",
      "        \n",
      "#print(\"Here is chain1\")\n",
      "#print(chain1)\n",
      "#print(\"Here is chain2\")\n",
      "#print(chain2)\n",
      "#print(\"Here is chain3\")\n",
      "#print(chain3)\n",
      "#print(\"Here is chain\")\n",
      "#print(chain4)\n",
      "#print(\"Here is chain5\")\n",
      "#print(chain5)\n",
      "#1.06826119571"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the value of n is: 8\n",
        "R_hat of x1: 112.068273081\n",
        "R_hat of x2: 35.4578559756\n",
        "R_hat:112.068273081\n",
        "the value of n is: 16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 26.8904177649\n",
        "R_hat of x2: 36.380492363\n",
        "R_hat:36.380492363\n",
        "the value of n is: 32"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 21.1835943059\n",
        "R_hat of x2: 22.1864545456\n",
        "R_hat:22.1864545456\n",
        "the value of n is: 64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 19.4964291842\n",
        "R_hat of x2: 18.5345825593\n",
        "R_hat:19.4964291842\n",
        "the value of n is: 128"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 26.6353025489\n",
        "R_hat of x2: 26.5783957326\n",
        "R_hat:26.6353025489\n",
        "the value of n is: 256"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 9.49349706048\n",
        "R_hat of x2: 10.7491852537\n",
        "R_hat:10.7491852537\n",
        "the value of n is: 512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 5.94484390308\n",
        "R_hat of x2: 5.64517599899\n",
        "R_hat:5.94484390308\n",
        "the value of n is: 1024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 2.67424801933\n",
        "R_hat of x2: 4.41536198079\n",
        "R_hat:4.41536198079\n",
        "the value of n is: 2048"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 2.35750424381\n",
        "R_hat of x2: 1.95339544671\n",
        "R_hat:2.35750424381\n",
        "the value of n is: 4096"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x1: 1.30935286024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "R_hat of x2: 1.05752396461\n",
        "R_hat:1.30935286024\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-120-7801a3a3c58a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mchain2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mchain3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mchain4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mchain5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the value of n is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-120-7801a3a3c58a>\u001b[0m in \u001b[0;36mhmc\u001b[0;34m(x0, M, target, epsilon0, L)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgnew\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m   \u001b[0;31m# make half-step in p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mxnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxnew\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m    \u001b[0;31m# make step in x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mgnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnew\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# find new gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgnew\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m   \u001b[0;31m# make half-step in p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mlogPnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnew\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# find new value of H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/robinmagpie/.local/lib/python3.5/site-packages/autograd/errors.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_extra_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/robinmagpie/.local/lib/python3.5/site-packages/autograd/convenience_wrappers.py\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/robinmagpie/.local/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp_maker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/robinmagpie/.local/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node, start_node)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcur_outgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             outgrad = function.vjp(argnum, cur_outgrad[0], node,\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Exact rejection ABC\n",
      "\n",
      "Develop an ABC sampler to estimate the probability $\\pi$ of success in a negative binomial model where exactly $N+n$ trials are needed to obtain $n$ successes and $N$ failures with the last trial being successful. (Note: this is the definition of the negative binomial distribution used by NumPy e.g. in `numpy.random.negative_binomial()`.)\n",
      "\n",
      "We assume that $n = 20$ and the data $X$ consists of a single observation $N = 50$.\n",
      "\n",
      "1. Report the mean and standard deviation of the posterior $p(\\pi | X)$ when the prior $p(\\pi) = \\mathrm{Beta}(\\pi; 1.0, 1.0)$.\n",
      "2. Report the mean and standard deviation of the posterior $p(\\pi | X)$ when the prior $p(\\pi) = \\mathrm{Beta}(\\pi; 5.0, 5.0)$.\n",
      "\n",
      "The required tolerance is $\\pm 0.005$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def abc_coinflip(L, N, n):\n",
      "    samples = []\n",
      "    nsamples = 0\n",
      "    while nsamples < N:\n",
      "        p = npr.beta(alpha,beta)\n",
      "        if npr.negative_binomial(20,p) == N:\n",
      "            samples.append(p)\n",
      "            nsamples += 1\n",
      "    return samples\n",
      "\n",
      "alpha = 1\n",
      "beta = 1\n",
      "x = abc_coinflip(10000000, 50, 20)\n",
      "h = plt.hist(x, 30)\n",
      "print(\"Mean of the posterior pi is:\")\n",
      "print(np.mean(x))\n",
      "print(\"Standard deviation of the posterior pi is:\")\n",
      "print(np.std(x))\n",
      "\n",
      "alpha = 5.0\n",
      "beta = 5.0\n",
      "x = abc_coinflip(10000000, 50, 20)\n",
      "h = plt.hist(x, 30)\n",
      "print(\"Mean of the posterior pi is:\")\n",
      "print(np.mean(x))\n",
      "print(\"Standard deviation of the posterior pi is:\")\n",
      "print(np.std(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean of the posterior pi is:\n",
        "0.294123666918\n",
        "Standard deviation of the posterior pi is:\n",
        "0.0546253765719\n",
        "Mean of the posterior pi is:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.3137364144\n",
        "Standard deviation of the posterior pi is:\n",
        "0.050833366327\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlArrom1SRQAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f0295a0b2b0>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Rejection ABC for continuous observations\n",
      "\n",
      "In this task we will develop an ABC sampler for the autoregressive (AR) model:\n",
      "$$ x_{t+1} = a x_t + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2). $$\n",
      "We assume $x_0 = 1$. The model has two parameters, $a$ and $\\sigma$. We set priors\n",
      "$$ p(a) = \\mathrm{Uniform}(a;\\; 0, 1), \\quad p(\\sigma) = \\mathrm{Gamma}(\\sigma;\\; k_\\sigma, \\theta_\\sigma) $$\n",
      "with $k_\\sigma = 5, \\theta_\\sigma = 1/8$. Note that we use the shape/scale parametrisation also used by NumPy and that the prior is over $\\sigma$, not $\\sigma^2$ (also more consistent with NumPy parametrisation).\n",
      "\n",
      "1. Implement a function to simulate the AR process. Test your function by generating and plotting two independent realisations of length 200 with $a = 0.75$, $\\sigma = 0.2$. Notice how the sequences diverge relatively quickly and are essentially independent toward the end.\n",
      "2. Implement an ABC sampler to infer the posterior over $a$ and $\\sigma$ given the single observed sequence loaded below using the summary statistics\n",
      "$$ S(X) = \\left( \\frac{1}{N} \\sum_{i=1}^N x_i^2, \\frac{1}{N-1} \\sum_{i=1}^{N-1} x_i x_{i+1} \\right). $$\n",
      "Run your sampler to generate samples with acceptance threshold $\\| S(X) - S(X^*)\\|_2 \\le \\epsilon$ with $\\epsilon = 0.1$.\n",
      "3. Report the approximate posterior means of $a$ and $\\sigma$ to Moodle.\n",
      "\n",
      "The required tolerance is $\\pm 0.03$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import autograd.numpy as np\n",
      "import autograd.numpy.random as npr\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import math as math\n",
      "\n",
      "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/ar_time_series_data.txt', header=None, sep='\\t')\n",
      "data = dataframe.values[:,0]\n",
      "plt.plot(data)\n",
      "\n",
      "def simulate_AR(a,sigma):\n",
      "    x_t = 1\n",
      "    x = []\n",
      "    x.append(x_t)\n",
      "    for i in range(0,len(data)):\n",
      "        epsilon_t = npr.normal(0,sigma)\n",
      "        x_t = a*x_t +  epsilon_t\n",
      "        x.append(x_t)\n",
      "    return x\n",
      "\n",
      "def compute_S(D):\n",
      "    x_square_sum = 0\n",
      "    x_i_x_iplus1_sum = 0\n",
      "    for i in range(0,len(D)-1):\n",
      "        x_square_sum = x_square_sum + D[i]**2\n",
      "        x_i_x_iplus1_sum = x_i_x_iplus1_sum + D[i]*D[i+1]\n",
      "    \n",
      "    x_square_sum = x_square_sum + D[len(D)-1]\n",
      "    x = []\n",
      "    x.append(x_square_sum/len(D))\n",
      "    x.append(x_i_x_iplus1_sum/(len(D)-1))\n",
      "    return x\n",
      "\n",
      "print(compute_S(data))\n",
      "\n",
      "S_data = compute_S(data)\n",
      "\n",
      "aas = []\n",
      "sigmas = []\n",
      "\n",
      "for i in range(0,100000):\n",
      "    if i%10000 == 0:\n",
      "        print(i)\n",
      "    a = npr.uniform()\n",
      "    sigma = npr.gamma(5,.125)\n",
      "    x = simulate_AR(a,sigma)\n",
      "    S_x = compute_S(x)\n",
      "    if math.sqrt((S_data[0]-S_x[0])**2 + (S_data[1]-S_x[1])**2) <= .1:\n",
      "        aas.append(a)\n",
      "        sigmas.append(sigma)\n",
      "\n",
      "print(np.mean(aas))\n",
      "print(np.mean(sigmas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1.3037196543195149, 1.1849257157301305]\n",
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "70000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "90000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.885964363271"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.528587754316\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f029b56d518>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 4. Variational approximation to a density\n",
      "\n",
      "Find the optimal normal distribution variational approximations $q_i(x)$ to the following densities:\n",
      "\n",
      "1. $p_1(x) = \\frac{1}{2} \\mathcal{N}(x;\\; 0, 1^2) + \\frac{1}{4} \\mathcal{N}(x;\\; 0, 2^2) + \\frac{1}{4} \\mathcal{N}(x;\\; 0, 3^2)$\n",
      "2. $p_2(x) = \\frac{1}{3} \\mathcal{N}(x;\\; 0, 1^2)\n",
      "           + \\frac{1}{3} \\mathcal{N}(x;\\; 0, 2^2)\n",
      "           + \\frac{1}{6} \\mathcal{N}(x;\\; 0, 3^2)\n",
      "           + \\frac{1}{6} \\mathcal{N}(x;\\; 1, 4^2)$\n",
      "\n",
      "Report the standard deviation $c$ obtained in each case and $m$ obtained for $q_2(x)$ to Moodle. The required tolerance is $\\pm 0.05$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5. Variational inference for a mixture model\n",
      "\n",
      "Estimate the posterior for the mixing proportion $\\pi$ and means $\\mu_1, \\mu_2$ in the normal mixture model\n",
      "$$ p(x_i | \\pi, \\mu_1, \\mu_2) = \\pi \\mathcal{N}(x_i;\\; \\mu_1, 1^2) + (1-\\pi) \\mathcal{N}(x_i;\\; \\mu_2, 1^2) $$\n",
      "for the data set loaded below.\n",
      "\n",
      "In order to ensure $0 \\le \\pi \\le 1$, we will reparametrise it using the logistic transformation as $\\pi = 1 / (1 + \\exp(-\\gamma))$. We will use normal priors for $\\mu_1, \\mu_2$ and a logistic-normal prior for $\\pi$, which is equivalent to setting a normal prior for $\\gamma$. The exact priors are\n",
      "$$ p(\\mu_1) = \\mathcal{N}(\\mu_1;\\; 0, \\sqrt{10}^2) \\quad \n",
      "   p(\\mu_2) = \\mathcal{N}(\\mu_2;\\; 0, \\sqrt{10}^2) \\quad\n",
      "   p(\\gamma) = \\mathcal{N}(\\gamma;\\; 0, 1.78^2). $$\n",
      "\n",
      "Fit normal distributions as variational approximations $q(\\mu_1)$, $q(\\mu_2)$ and $q(\\gamma)$ to the posterior distribution of the model.\n",
      "\n",
      "Report the means and standard deviations of $q(\\mu_1)$ and $q(\\mu_2)$, and the mean and standard deviation of $\\pi$ under $q(\\gamma)$ in Moodle. The required tolerance is $\\pm 0.03$.\n",
      "\n",
      "Hint: computing the mean and standard deviation of $\\pi$ requires extra effort because the approximation $q(\\gamma)$ is over $\\gamma$. The easiest way to solve this problem is to draw a number of samples from $q(\\gamma)$, transform those to $\\pi$ and compute the mean and standard deviation of the transformed samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import autograd.numpy as np\n",
      "import autograd.numpy.random as npr\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/mixture_data.txt', header=None, sep='\\t')\n",
      "data = dataframe.values[:,0]\n",
      "print(np.mean(data), np.std(data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}